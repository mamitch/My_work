{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:  What was the biggest problem with decision trees?\n",
    "\n",
    "One of the major drawbacks of decision trees is that they overfit the data and do not generalize well to new data.\n",
    "\n",
    "Ensemble methods can help tackle this problem by training a group of decision tree classifiers on different random subsets of the training data and then combining the predictions of the individual trees to make an even more powerful prediction.\n",
    "\n",
    "Two most common Ensemble models are **Random Forests** and **Gradient Boosted Trees** although there are many more you can learn about.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By the end of the lesson students will be able to \n",
    "- Differentiate between decision trees and random forest \n",
    "- Explain what makes random forest so powerful\n",
    "- Build a random forest in `sklearn`\n",
    "- Explore the fine-tuning options in `sklearn` for random forest\n",
    "\n",
    "\n",
    "\n",
    "Bonus Objectives:\n",
    "- Differentiate between random forest and boosting methods\n",
    "- Build a gradient boosted model in `sklearn`\n",
    "- Explore the fine-tuning options in `sklearn` for gradient boosted models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forest\n",
    "### aka, a lot of random trees\n",
    "\n",
    "![forest](img/forest.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scenario: \n",
    "We've made a decision tree, but we are concerned it might not generalize well. What to do?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Could use k-fold cross validation\n",
    "\n",
    "![dectree](img/decisiontree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But with same data, might get same results\n",
    "![same](img/sameresult.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### It's like crowd sourcing. \n",
    "Could ask a lot of **_similar_** people\n",
    "![min](img/minions.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or could ask a more _**diverse**_ group of people\n",
    "![waldo](img/waldo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Want to create a more diverse set of trees\n",
    "\n",
    "![forest](img/randomforest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do you diversify?\n",
    "\n",
    "You create $m$ trees that randomly sample from the your data.<br>\n",
    "Then at each node, $p$ features are randomly chosen to be considered when splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mind](img/mindblown.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specifics:\n",
    "\n",
    " $m$ trees defaults to 100 unless otherwise specified.<br>\n",
    " $p$ features defaults to square root of total features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "This technique is called _bagging_ because the samples are **_bootstrapped_** and then the results of each tree are **_aggregated_**\n",
    "\n",
    "![bag](img/bag.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src= \"./img/rand_forest_diagram.png\" style = \"width: 600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built in cross-validation\n",
    "\n",
    "Because each tree is made on a **sample**, the algorithm also calculates the **Out of Bag**(OOB) Error averaged for each tree. \n",
    "\n",
    "<img src= \"./img/oob.png\" width= 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to the diabetes scenario\n",
    "\n",
    "Let's start with a basic decision tree that we can use to compare to our new and improved Ensemble methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for decision trees\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New ones for random forest\n",
    "\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.drop(columns=['Outcome'])\n",
    "Y = diabetes['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state= 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=10)  \n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_train,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUC is :{0}\".format(round(roc_auc,2)))\n",
    "\n",
    "# Create and print a confusion matrix \n",
    "plot_confusion_matrix(classifier, X_train, y_train, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "1. Create a second DT classifier but now use entropy as the criterion and max depth =5.\n",
    "\n",
    "2. Fit the model on the training data\n",
    "\n",
    "3. Print the accuracy, AUC, and confusion matrix.\n",
    "\n",
    "4. Use `cross_val_score` to see how this model generalizes.\n",
    "\n",
    "4. Compare this model to our previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances!\n",
    "\n",
    "We also can obtain the feature importances of our tree based models.  These rates how important each feature is for a decision a tree makes.  It is a number between 0 and 1 for each feature where 0 indicates the feature is \"not used at all\" and 1 means the feature \"perfectly predicts the target\".\n",
    "\n",
    "Feature importances always sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier2.feature_importances_)\n",
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "plot_feature_importances(classifier2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to Random Forests\n",
    "\n",
    "Let's create a random forest which has 100 trees and has a max_depth of 5.\n",
    "\n",
    "\n",
    "In sklearn the number of trees is set by the `n_estimators` parameter and the number of features used per tree is set by the `max_features` parameter.\n",
    "\n",
    "`n_estimators` = $m$<br>\n",
    "`max_features` = $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 5, oob_score=True, bootstrap=True)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get accuracy of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get oob score to see how this will generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_train)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(forest, X_train, y_train, cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is our random forest model better than our decision tree?  Did the feature importances change?  How so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us try to fine tune this model a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters for Random Forests\n",
    "\n",
    "`n_estimators` : the number of trees in the forest<br>\n",
    "`criterion`: “gini”,”entropy” <br>\n",
    "`max_features`: the number of random features to be considered when looking for the best split <br>\n",
    "`max_depth`:  the maximum number of levels of a tree<br>\n",
    "`bootstrap`: whether or not bootstrap samples are used to build trees <br>\n",
    "`oob_score`: whether or not to use out-of-bag samples to estimate the generalization accuracy<br>\n",
    "`n_jobs`: how many cores you want to use when training your trees<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "In your group:\n",
    "\n",
    "- pick at least 3 hyperparameters above to tune your model using gridsearch or randomizedsearch\n",
    "- fit your search method to your training data\n",
    "- use the best parameters to run a \"best random forest model\"\n",
    "- print the accuracy score, oob score, AUC and confusion matrix of this model\n",
    "- make a visualization of the feature importances like we did with our decision tree model\n",
    "- compare the performance of the random forest model to `classifier2`.  Which is the better model?  Why do you say that?  What are the risks of making false positives and false negatives in the context of this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR COMPARISON HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Benefits\n",
    "**Strong performance**: The Random Forest algorithm usually has very strong performance on most problems, when compared with other classification algorithms. Because this is an ensemble algorithm, the model is naturally resistant to noise and variance in the data, and generally tends to perform quite well.\n",
    "\n",
    "**Interpretability**: Conveniently, since each tree in the Random Forest is a Glass-Box Model (meaning that the model is interpretable, allowing us to see how it arrived at a certain decision), the overall Random Forest is, as well! You'll demonstrate this yourself in the upcoming lab, by inspecting feature importances for both individual trees and the entire Random Forest itself.\n",
    "\n",
    "### Drawbacks\n",
    "**Computational Complexity**: Like any ensemble method, training multiple models means paying the computational cost of training each model. On large datasets, the runtime can be quite slow compared to other algorithms.\n",
    "\n",
    "**Memory Usage**: Another side effect of the ensembled nature of this algorithm, having multiple models means storing each in memory. Random Forests tend to have a larger memory footprint that other models. Whereas a parametric model like a Logistic Regression just needs to store each of the coefficients, a Random Forest has to remember every aspect of every tree! It's not uncommon to see larger Random Forests that were trained on large datasets have memory footprints in the 10s, or even hundreds of MB. For data scientists working on modern computers, this isn't typically a problem--however, there are special cases where the memory footprint can make this an untenable choice--for instance, an app on a smartphone that uses machine learning may not be able to afford to spend that much disk space on a Random Forest model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to consider\n",
    "\n",
    "How do Random Forests handle the bias-variance tradeoff? <br>\n",
    "What would be another way of using ensembling methods to tackle the bias-variance tradeoff?\n",
    "\n",
    "Additional Resources on Random Forests\n",
    "\n",
    "- https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "- https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
    "\n",
    "- [Sklearn averages probabilities in RF implementation](https://scikit-learn.org/stable/modules/ensemble.html#forest)\n",
    "\n",
    "- [On the variance](https://newonlinecourses.science.psu.edu/stat414/node/167/)\n",
    "\n",
    "- [Is RF immune to overfitting?](https://en.wikipedia.org/wiki/Talk%3ARandom_forest)\n",
    "\n",
    "- [Tricky stuff with respect to feature importance](http://rnowling.github.io/machine/learning/2015/08/10/random-forest-bias.html)\n",
    "\n",
    "- [An interesting implementation of feature importance](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances_faces.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-faces-py)\n",
    "\n",
    "- [Different Ensemble Methods in sklearn](https://scikit-learn.org/stable/modules/ensemble.html#forest)\n",
    "\n",
    "- [ISLR - section 8.2](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "- [Another library for RF: H2o](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html)\n",
    "\n",
    "\n",
    "Another flatiron slidedeck [here](https://docs.google.com/presentation/d/1bUwvdvg4bDRVzE3YaLSQZcsx-7t2ZFnaEGxjQHjxAoc/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus section:  Gradient Boosting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates a number of weak learners (decision trees that do only slightly better than random chance)\n",
    "- Use weak learners to make predictions on training set. \n",
    "- Increase importance of observations where predictions were incorrect. \n",
    "- Decrease importance of observations where predictions were correct. \n",
    "- Train another batch of weak learners on training data with tweaked importances\n",
    "\n",
    "\n",
    "![](./img/bagging_vs_boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Benefits\n",
    "\n",
    "- Often has best-in-class performance compared to other models\n",
    "- Can be used for Classification/Regression\n",
    "- Some explainability (feature importances)\n",
    "- Works well without scaling features\n",
    "- Can use with mix of binary and continuous features\n",
    "\n",
    "\n",
    "### Drawbacks\n",
    "\n",
    "- Require careful tuning \n",
    "- May take a long time to train\n",
    "- Often does not do well with high dimensional sparse data\n",
    "- Larger/more computationally expensive than other shallow algorithms\n",
    "- Regression predictions bounded by largest/smallest observations seen\n",
    "- Model still mostly black-box due to complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters to tune\n",
    "\n",
    "`n_estimators` : number of trees to make\n",
    "\n",
    "`learning_rate` : degree to which each tree is allowed to correct mistakes of previous trees\n",
    "\n",
    "`max_depth` and `max_leaf_nodes` also are helpful to reduce the complexity of each tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "\n",
    "Use the [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) in sklearn to do the following steps:\n",
    "\n",
    "- Instantiate a \"vanilla\" gradient boosting classifier\n",
    "- fit your search method to your training data\n",
    "- use the best parameters to run a \"best random forest model\"\n",
    "- print the score, AUC and confusion matrix of this model\n",
    "- make a visualization of the feature importances like we did our models above\n",
    "- compare the performance of this model with your best random forest model.  Which is the better model?  Why do you say that?  What are the risks of making false positives and false negatives in the context of this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test!\n",
    "\n",
    "Using the best model you have produced for our diabetes data today, compute the accuracy on the test dataset.  How did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional resources on boosting\n",
    "\n",
    "* SciKit-Learn Implementations\n",
    "\n",
    "    * https://scikit-learn.org/stable/modules/ensemble.html#adaboost\n",
    "\n",
    "    * https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting\n",
    "\n",
    "    * https://scikit-learn.org/stable/modules/ensemble.html#histogram-based-gradient-boosting\n",
    "\n",
    "* Non-SciKit-Learn Implementations\n",
    "\n",
    "    * https://github.com/catboost/catboost\n",
    "\n",
    "    * https://github.com/microsoft/LightGBM\n",
    "\n",
    "    * https://github.com/jhwjhw0123/Imbalance-XGBoost\n",
    "\n",
    "    * https://github.com/dmlc/xgboost\n",
    "\n",
    "    * https://github.com/stanfordmlgroup/ngboost\n",
    "\n",
    "* Background\n",
    "\n",
    "    * https://en.wikipedia.org/wiki/Gradient_boosting\n",
    "\n",
    "    * https://explained.ai/gradient-boosting/index.html\n",
    "\n",
    "    * https://en.wikipedia.org/wiki/AdaBoost\n",
    "\n",
    "    * https://en.wikipedia.org/wiki/XGBoost\n",
    "\n",
    "* Other\n",
    "\n",
    "    * https://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py\n",
    "\n",
    "    * https://github.com/szilard/GBM-perf\n",
    "\n",
    "    * https://github.com/talperetz/awesome-gradient-boosting#notebooks\n",
    "\n",
    "    * https://nbviewer.jupyter.org/github/jphall663/interpretable_machine_learning_with_python/blob/master/dt_surrogate_loco.ipynb\n",
    "    \n",
    "    * https://github.com/limexp/xgbfir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

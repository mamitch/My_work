{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"img/pipelines.png\" style=\"height:450px\">\n",
    "\n",
    "\n",
    "[Image Source](https://towardsdatascience.com/using-functiontransformer-and-pipeline-in-sklearn-to-predict-chardonnay-ratings-9b13fdd6c6fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agenda__\n",
    "\n",
    "- Pipelines and Composite estimators\n",
    "\n",
    "- Why do we need them?\n",
    "\n",
    "- How to use them in sklearn: accessing a particular object in pipe and changing parameters\n",
    "\n",
    "- Combining pipelines with gridsearch\n",
    "\n",
    "- Summary and further reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "__What is a Pipeline?__\n",
    "\n",
    "_Transformers:_ Any object with .transform method. Ex: PCA, OneHotEncoder.\n",
    "\n",
    "_Estimators:_ Any object with predict method. Ex: RandomForestClassifier, LinearRegression etc.\n",
    "\n",
    "_Pipelines:_ A tool for combining transformers with estimators. \n",
    "\n",
    "\n",
    "__Other relevant tools are:__\n",
    "\n",
    "- FutureUnion\n",
    "\n",
    "- TransformedTargetRegressor\n",
    "\n",
    "__Why do we need pipelines?__\n",
    "\n",
    "- Convenience and encapsulation\n",
    "\n",
    "Even though we train 10 transformers and 5 estimators we will call fit and predict once.\n",
    "\n",
    "- Joint parameter selection - here emphasize preprocessing part\n",
    "\n",
    "We can put pipelines into gridsearch and find best parameters for all the estimators at once.\n",
    "\n",
    "- Safety\n",
    "\n",
    "Pipelines help avoid leaking statistics from your test data into trained model.\n",
    "\n",
    "[Pipelines and Composite Estimators](https://scikit-learn.org/stable/modules/compose.html#combining-estimators)\n",
    "\n",
    "\n",
    "\n",
    "## Usage of Pipelines\n",
    "\n",
    "The Pipeline is built using a list of (key, value) pairs, where the key is a string containing the name you want to give this step and value is an estimator object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "estimators = [('imputer', SimpleImputer()),('reduce_dim', PCA()), ('clf', SVC())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "pipe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Create your own pipeline. You can use the same transformers and estimators with different parameters and 'name'.\n",
    "\n",
    "- You can create a new pipe with a scaler also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('imputer', SimpleImputer()),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('clf', LogisticRegression(C=1000,\n",
    "                                            max_iter=1000,\n",
    "                                            solver='saga'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also gives us \"make_pipeline\" which is almost the same thing but with make_pipeline you don't have to give names.\n",
    "\n",
    "__Your Turn__\n",
    "\n",
    "-  [Check documentation: 6.1.1.1.1. Construction](https://scikit-learn.org/stable/modules/compose.html) and use make_pipeline to construct an pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-10 supplement.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing steps\n",
    "\n",
    "We have multiple ways to access and object in the pipeline\n",
    "\n",
    "- steps attribute\n",
    "\n",
    "- [idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that these will all give the simple imputer object\n",
    "pipe.steps[0]\n",
    "\n",
    "pipe['simpleimputer']\n",
    "\n",
    "pipe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also access a particular object by named_steps\n",
    "## sklearn claims that tab completion should work here but \n",
    "## in my notebook it didn't\n",
    "\n",
    "pipe.named_steps.simpleimputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can 'slice' pipelines to create sub-pipes\n",
    "\n",
    "pipe[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the parameters\n",
    "\n",
    "Parameters of the estimators in the pipeline can be accessed using the \n",
    "\"estimator__parameter\" syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(clf__C = 10)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching Transformers\n",
    "\n",
    "[(6.1.1.3. Caching transformers: avoid repeated computation)](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of caching transformers:\n",
    "\n",
    "1. Use mkdtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "estimators = [('reduce_dim', PCA()), ('clf', LinearRegression())]\n",
    "cachedir = mkdtemp()\n",
    "pipe = Pipeline(estimators, memory=cachedir)\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the cache directory when you don't need it anymore\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by giving a string as the directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(estimators, memory='cached_transformers')\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## again remove it when you are done with them\n",
    "rmtree('cached_transformers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming target in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_boston(return_X_y=True)\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "regressor = LinearRegression()\n",
    "regr = TransformedTargetRegressor(regressor=regressor,\n",
    "                                  transformer=transformer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print('R2 score: {0:.2f}'.format(regr.score(X_test, y_test)))\n",
    "\n",
    "raw_target_regr = LinearRegression().fit(X_train, y_train)\n",
    "print('R2 score: {0:.2f}'.format(raw_target_regr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also access the parameters in the gridsearch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(simpleimputer__strategy=['mean', 'median'],\n",
    "                  svc__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)\n",
    "\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note also that we can choose to skip some steps in the pipeline\n",
    "\n",
    "param_grid = dict(reduce_dim=['passthrough', PCA(5), PCA(6)],\n",
    "                  svc=[SVC(gamma='auto'),\n",
    "                       LogisticRegression(solver='lbfgs', max_iter=1000)],\n",
    "                  svc__C=[0.1, 10, 100])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/diabetes.csv')\n",
    "display(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.Outcome\n",
    "column_list = df.columns.tolist()\n",
    "\n",
    "column_list.remove('Outcome')\n",
    "print(column_list)\n",
    "\n",
    "data = df[column_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[On Scaling data](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    target,\n",
    "                                                    test_size=0.20,\n",
    "                                                    stratify=target,\n",
    "                                                    random_state=120919)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Create a pipeline and use this pipeline for fitting and predicting diabetes results for the above data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-10 supplement.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Now use gridsearch with pipelines and return the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 13-22 supplement.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark__\n",
    "\n",
    "\n",
    "Note that even if gridsearch and pipes are getting along very well. The options are not limitless. Try to add Randomforests as classifier in the gridsearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further research and miscellaneous\n",
    "\n",
    "- [FeatureUnion](https://scikit-learn.org/stable/modules/compose.html#featureunion-composite-feature-spaces)\n",
    "\n",
    "- [ColumnTransformer](https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data)\n",
    "\n",
    "- [sklearn, dictionary of terms](https://scikit-learn.org/stable/glossary.html#term-transformer)\n",
    "\n",
    "- [Pydata meeting on pipelines](https://www.youtube.com/watch?v=BFaadIqWlAg)\n",
    "\n",
    "- [Another pydata talk on pipelines with FeatureUnion](https://www.youtube.com/watch?v=URdnFlZnlaE)\n",
    "\n",
    "- [On scalers](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler)\n",
    "\n",
    "- [A nice notebook on pipelines](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
